# data-cleaning
Data Cleaning and Preprocessing using Python (Titanic Dataset)

## ğŸ§  Objective
To clean and prepare a raw dataset (Titanic) for Machine Learning by handling missing values, encoding categorical variables, scaling features, removing outliers, and visualizing data.

## ğŸ§° Tools Used
- Python
- Pandas
- NumPy
- Seaborn & Matplotlib
- Scikit-learn

## ğŸ“ Files Included
- `dataset/Titanic-Dataset.csv` - Titanic dataset.
- `code/data_cleaning.ipynb` - Jupyter Notebook with all steps implemented.
- `report/Data_Cleaning_Preprocessing_Report.pdf` - Final summary report.

## ğŸ” Key Steps
1. Imported and explored the dataset.
2. Handled missing values (`Age`, `Embarked`, dropped `Cabin`).
3. Encoded categorical variables using Label and One-Hot Encoding.
4. Standardized numerical features using `StandardScaler`.
5. Detected and removed outliers using Z-score.
6. Visualized data using boxplots  and a heatmap.

---

## ğŸ“š What I Learned
- Real-world data is messy and needs cleaning before ML.
- The importance of feature encoding and scaling.
- How preprocessing impacts model performance.
